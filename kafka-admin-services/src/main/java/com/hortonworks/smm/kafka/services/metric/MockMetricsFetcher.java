/*
 *   HORTONWORKS DATAPLANE SERVICE AND ITS CONSTITUENT SERVICES
 *
 *   (c) 2016-2018 Hortonworks, Inc. All rights reserved.
 *
 *   This code is provided to you pursuant to your written agreement with Hortonworks, which may be the terms of the
 *   Affero General Public License version 3 (AGPLv3), or pursuant to a written agreement with a third party authorized
 *   to distribute this code.  If you do not have a written agreement with Hortonworks or with an authorized and
 *   properly licensed third party, you do not have any rights to this code.
 *
 *   If this code is provided to you under the terms of the AGPLv3:
 *   (A) HORTONWORKS PROVIDES THIS CODE TO YOU WITHOUT WARRANTIES OF ANY KIND;
 *   (B) HORTONWORKS DISCLAIMS ANY AND ALL EXPRESS AND IMPLIED WARRANTIES WITH RESPECT TO THIS CODE, INCLUDING BUT NOT
 *     LIMITED TO IMPLIED WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE;
 *   (C) HORTONWORKS IS NOT LIABLE TO YOU, AND WILL NOT DEFEND, INDEMNIFY, OR HOLD YOU HARMLESS FOR ANY CLAIMS ARISING
 *     FROM OR RELATED TO THE CODE; AND
 *   (D) WITH RESPECT TO YOUR EXERCISE OF ANY RIGHTS GRANTED TO YOU FOR THE CODE, HORTONWORKS IS NOT LIABLE FOR ANY
 *     DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, PUNITIVE OR CONSEQUENTIAL DAMAGES INCLUDING, BUT NOT LIMITED TO,
 *     DAMAGES RELATED TO LOST REVENUE, LOST PROFITS, LOSS OF INCOME, LOSS OF BUSINESS ADVANTAGE OR UNAVAILABILITY,
 *     OR LOSS OR CORRUPTION OF DATA.
 */
package com.hortonworks.smm.kafka.services.metric;

import com.hortonworks.smm.kafka.services.management.TopicManagementService;
import com.hortonworks.smm.kafka.services.management.dtos.BrokerNode;
import com.hortonworks.smm.kafka.services.management.dtos.TopicInfo;
import com.hortonworks.smm.kafka.services.management.dtos.TopicPartition;
import com.hortonworks.smm.kafka.services.management.dtos.TopicPartitionInfo;
import com.hortonworks.smm.kafka.services.metric.ams.AMSMetricDescriptorSupplier;
import com.hortonworks.smm.kafka.services.metric.ams.AMSMetricsFetcher;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.concurrent.ThreadLocalRandom;
import java.util.concurrent.TimeUnit;

/**
 * <p>MockMetricsFetcher behaves like AMSMetricsFetcher which responds to metric requests and provides the response.
 * The generated metric value would be monotonically increasing value on each unique request. For RATE metric request,
 * any value between 0.0 to 1.0 would be provided. The following metric requests are handled: </p>
 * <p>
 * Broker metrics operation: (autogenerated)
 * Run at-least one Kafka broker to get the metrics.
 * - bytesInCountPerSec, bytesOutCountPerSec and messagesInCountPerSec metric values are autogenerated.
 * - discMetrics, cpuMetrics and ioMetrics are not handled.
 * <p>
 * Consumer Group related details: (valid / non-autogenerated)
 * Run at-least one Consumer group process to get the metrics.
 * - provides consumer group details for all the clients.
 * - provides the consumer group details, for a given clientId.
 * - provides all the consumer group names.
 * - provides the group-details for all the groups.
 * - provides the group-details, for a given groupName.
 * <p>
 * Producer metrics operations: (auto-generated)
 * No need to start any process.
 * - provides autogenerated (clientId, outMessagesCount) producer metrics.
 * - provides autogenerated (clientId, outMessagesCount) producer metrics, for a given producerId.
 * <p>
 * Topic metrics operation: (auto-generated)
 * Create at-least one topic with one or more partitions to get the metrics.
 * - messageInCount, bytesInCount, bytesOutCount, partitionMetrics are auto-generated.
 */
public class MockMetricsFetcher implements MetricsFetcher {

    // NOTE: It is assumed that all the MetricName tags would be provided for handling wild-cards.
    private static final Logger LOG = LoggerFactory.getLogger(MockMetricsFetcher.class);

    private final Map<MetricDescriptor, Double> previousGenValMap = new HashMap<>();
    private final Map<MetricDescriptor, Map<Long, Double>> lastFetchedMetrics = new HashMap<>();
    private TopicManagementService topicMgmtService;

    private final List<String> consumerGroupNames = new ArrayList<>();
    private static final String[] clientIds = {"sushi", "bubbles", "casper", "shadow", "comet", "flash", "blue",
            "crimson", "spike", "spot"};

    public MockMetricsFetcher(TopicManagementService topicMgmtService) {
        this.topicMgmtService = topicMgmtService;
    }

    @Override
    public Map<MetricDescriptor, Map<Long, Double>> getBrokerMetrics(BrokerNode brokerNode,
                                                                     long startTimeMs,
                                                                     long endTimeMs,
                                                                     Collection<MetricDescriptor> metricDescriptors) {
        return getMetrics(startTimeMs, endTimeMs, metricDescriptors);
    }

    @Override
    public Map<MetricDescriptor, Map<Long, Double>> getHostMetrics(BrokerNode brokerNode,
                                                                   long startTimeMs,
                                                                   long endTimeMs,
                                                                   Collection<MetricDescriptor> metricDescriptors) {
        return getMetrics(startTimeMs, endTimeMs, metricDescriptors);
    }

    @Override
    public Map<MetricDescriptor, Map<Long, Double>> getClusterMetrics(long startTimeMs,
                                                                      long endTimeMs,
                                                                      Collection<MetricDescriptor> metricDescriptors) {
        return getMetrics(startTimeMs, endTimeMs, metricDescriptors);
    }

    @Override
    public MetricDescriptorSupplier getMetricDescriptorSupplier() {
        return new AMSMetricDescriptorSupplier();
    }

    @Override
    public boolean emitMetrics(Map<MetricDescriptor, Long> metrics) {
        metrics.forEach((descriptor, value) -> {
            if (descriptor.metricName().getTags().equals(AbstractMetricDescriptorSupplier.CONSUMER_GROUP_TAG)) {
                String consumerGroup = descriptor.queryTags().get(AbstractMetricDescriptorSupplier.CONSUMER_GROUP);
                consumerGroupNames.add(consumerGroup);
            }
            previousGenValMap.put(descriptor, (double) value);
        });
        return true;
    }

    @Override
    public void close() {
    }

    @Override
    public void configure(Map<String, ?> configs) {
    }

    public Map<MetricDescriptor, Map<Long, Double>> getLastFetchedMetrics() {
        return lastFetchedMetrics;
    }

    private synchronized Map<MetricDescriptor, Map<Long, Double>> getMetrics(long startTime,
                                                                             long endTime,
                                                                             Collection<MetricDescriptor> metricDescriptors) {
        Map<MetricDescriptor, Map<Long, Double>> metrics = new HashMap<>();
        AMSMetricsFetcher.Precision precision = AMSMetricsFetcher.getPrecision(startTime, endTime);
        int dataPoints = calculateDataPoints(startTime, endTime, precision);
        LOG.debug("startTimeMs : {}, endTimeMs : {}, precision : {}, dataPoints : {}", startTime, endTime, precision,
                dataPoints);
        for (MetricDescriptor descriptor : metricDescriptors) {
            // handles wild-card in tags
            List<MetricDescriptor> respDescriptors = createResponseDescriptor(descriptor);
            for (MetricDescriptor respDescriptor : respDescriptors) {
                PostProcessFunction postProcessFunction = respDescriptor.postProcessFunction();
                Map<Long, Double> metricValues = generateMetricValues(startTime, respDescriptor, precision,
                        postProcessFunction, dataPoints);

                // Broker metrics when used at cluster level have '%' wildcard as partition value, when returning back the results from
                // Metric service these wild cards must be resolved to appropriate values, here we are by default resolving to 0
                if (respDescriptor.queryTags().containsKey(AMSMetricDescriptorSupplier.PARTITION_NUMBER) &&
                        respDescriptor.queryTags().get(AMSMetricDescriptorSupplier.PARTITION_NUMBER).equals(MetricsService.WILD_CARD)) {
                    respDescriptor.queryTags().put(AMSMetricDescriptorSupplier.PARTITION_NUMBER, "0");
                }
                metrics.put(respDescriptor, metricValues);
            }
        }
        lastFetchedMetrics.clear();
        lastFetchedMetrics.putAll(metrics);
        return metrics;
    }

    private List<MetricDescriptor> createResponseDescriptor(MetricDescriptor descriptor) {
        List<TopicPartition> topicPartitions = new ArrayList<>();
        List<String> groupNames = new ArrayList<>();
        Map<String, String> queryTags = descriptor.queryTags();
        if (MetricsService.WILD_CARD.equals(queryTags.get(AMSMetricDescriptorSupplier.TOPIC)) &&
                MetricsService.WILD_CARD.equals(queryTags.get(AMSMetricDescriptorSupplier.PARTITION_NUMBER))) {
            topicMgmtService.allTopicInfos().forEach(topicInfo -> topicPartitions.addAll(getTopicPartitions(topicInfo)));
        } else if (MetricsService.WILD_CARD.equals(queryTags.get(AMSMetricDescriptorSupplier.PARTITION_NUMBER))) {
            String topic = queryTags.get(AMSMetricDescriptorSupplier.TOPIC);
            topicPartitions.addAll(getTopicPartitions(topicMgmtService.topicInfo(topic)));
        }

        Map<String, String> respQueryTags = new HashMap<>(queryTags);
        Random random = new Random();
        if (MetricsService.WILD_CARD.equals(queryTags.get(AMSMetricDescriptorSupplier.CLIENT_ID))) {
            respQueryTags.put(AMSMetricDescriptorSupplier.CLIENT_ID, clientIds[random.nextInt(clientIds.length)]);

            // removing some of the topic-partitions, otherwise it looks like producer pushes data for all tps
            int i = 0;
            Iterator<TopicPartition> iterator = topicPartitions.iterator();
            while (iterator.hasNext()) {
                iterator.next();
                if (i++ % 3 == 0)
                    iterator.remove();
            }
        } else if (MetricsService.WILD_CARD.equals(queryTags.get(AMSMetricDescriptorSupplier.CONSUMER_GROUP))) {
            if (consumerGroupNames.isEmpty()) {
                groupNames.add("DUMMY-CONSUMER-GROUP");
            } else {
                groupNames.addAll(consumerGroupNames);
            }
        }

        MetricDescriptor.MetricDescriptorBuilder respDescriptorBuilder = MetricDescriptor.newBuilder()
                .withAggregationFunction(descriptor.aggrFunction())
                .withPostProcessFunction(descriptor.postProcessFunction());

        if (topicPartitions.isEmpty() && groupNames.isEmpty()) {
            MetricDescriptor respDescriptor = respDescriptorBuilder
                    .withQueryTags(respQueryTags)
                    .build(descriptor.metricName());
            return Collections.singletonList(respDescriptor);
        } else {
            List<MetricDescriptor> respDescriptors = new ArrayList<>();
            for (TopicPartition tp : topicPartitions) {
                if (!groupNames.isEmpty()) {
                    for (String groupName : groupNames) {
                        Map<String, String> rqTags = new HashMap<>(respQueryTags);
                        rqTags.put(AMSMetricDescriptorSupplier.TOPIC, tp.topic());
                        rqTags.put(AMSMetricDescriptorSupplier.PARTITION_NUMBER, String.valueOf(tp.partition()));
                        rqTags.put(AMSMetricDescriptorSupplier.CONSUMER_GROUP, groupName);
                        MetricDescriptor respDescriptor = respDescriptorBuilder
                                .withQueryTags(rqTags)
                                .build(descriptor.metricName());
                        respDescriptors.add(respDescriptor);
                    }
                } else {
                    Map<String, String> rqTags = new HashMap<>(respQueryTags);
                    rqTags.put(AMSMetricDescriptorSupplier.TOPIC, tp.topic());
                    rqTags.put(AMSMetricDescriptorSupplier.PARTITION_NUMBER, String.valueOf(tp.partition()));
                    MetricDescriptor respDescriptor = respDescriptorBuilder
                            .withQueryTags(rqTags)
                            .build(descriptor.metricName());
                    respDescriptors.add(respDescriptor);
                }
            }
            return respDescriptors;
        }
    }

    private List<TopicPartition> getTopicPartitions(TopicInfo topicInfo) {
        List<TopicPartition> partitions = new ArrayList<>();
        for (TopicPartitionInfo tpInfo : topicInfo.partitions()) {
            partitions.add(new TopicPartition(topicInfo.name(), tpInfo.partition()));
        }
        return partitions;
    }

    private int calculateDataPoints(long fromMs,
                                    long toMs,
                                    AMSMetricsFetcher.Precision precision) {
        if (fromMs == -1 && toMs == -1)
            return 1;

        long timeDiffMs = toMs - fromMs;
        switch (precision) {
            case SECONDS:
                return (int) TimeUnit.MILLISECONDS.toSeconds(timeDiffMs) - 1;
            case MINUTES:
                return (int) (TimeUnit.MILLISECONDS.toMinutes(timeDiffMs) / 5) - 1;
            case HOURS:
                return (int) (TimeUnit.MILLISECONDS.toHours(timeDiffMs)) - 1;
            case DAYS:
                return (int) (TimeUnit.MILLISECONDS.toDays(timeDiffMs)) - 1;
        }
        return 1;
    }

    private Map<Long, Double> generateMetricValues(long startTimeMs,
                                                   MetricDescriptor descriptor,
                                                   AMSMetricsFetcher.Precision precision,
                                                   PostProcessFunction postProcessFunction,
                                                   int dataPoints) {
        Map<Long, Double> metricValues = new HashMap<>(dataPoints);
        long timestamp = (startTimeMs == -1) ? System.currentTimeMillis() : startTimeMs;
        ThreadLocalRandom localRandom = ThreadLocalRandom.current();
        for (int entry = 0; entry < dataPoints; entry++) {
            if (postProcessFunction == PostProcessFunction.RATE) {
                metricValues.put(timestamp, localRandom.nextDouble(1.0));
            } else {
                double nextVal = previousGenValMap.computeIfAbsent(descriptor, x -> localRandom.nextDouble(0, 1000));
                nextVal += localRandom.nextDouble(0, 1000);
                previousGenValMap.put(descriptor, nextVal);
                metricValues.put(timestamp, nextVal);
            }
            timestamp = getNextTimestamp(timestamp, precision);
        }
        return metricValues;
    }

    private long getNextTimestamp(long timestamp,
                                  AMSMetricsFetcher.Precision precision) {
        if (precision == null)
            return timestamp;

        switch (precision) {
            case SECONDS:
                return timestamp + 1000;
            case MINUTES:
                return timestamp + (5 * 60 * 1000);
            case HOURS:
                return timestamp + (60 * 60 * 1000);
            case DAYS:
                return timestamp + (24 * 60 * 60 * 1000);
        }
        return timestamp;
    }

}
